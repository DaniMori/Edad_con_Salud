---
title: "Correction of free-text variables in Cohort 2019 - Wave 1"
output:
  html_document: default
params:
  test: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, message=FALSE}
library(knitr)
library(ecs.data)
library(tidyverse)
library(lubridate)
library(haven)
library(glue)
library(readxl)
library(Statamarkdown)
library(waldo)
library(sessioninfo)

opts_chunk$set(echo = TRUE, results = 'markup')
```

```{r constants}
# Execution configuration: ----
IS_TEST <- params$test

# Data values and variables objects: ----

STATA_VERSION <- 13L

# File system objects: ----

## Current file structure:

### Folders:

DB_ROOT_DIR    <- read_ecs_folder("DB")
CCOVID_SUBDIR <- "Subestudio_COVID"
HISTORY_SUBDIR <- "Antiguas"
CCOVID_DIR    <- file.path(DB_ROOT_DIR, CCOVID_SUBDIR)
HISTORY_DIR    <- file.path(CCOVID_SUBDIR, HISTORY_SUBDIR)

### Files:

CURRENT_FILENAME   <- "Edad_con_salud_Fichero_Completo.dta"
RESTORE_FILENAME   <- "snapshot_2022-03-10_12-50.dta"
# The backup file name is constructed with the "current date and time" object
BACKUP_FILENAME    <- "snapshot_2023-03-09_12-50.dta" |> glue()
CHANGELOG_FILENAME <- "Modificaciones_BBDD_COVID-19_substudy.xlsx"

### File paths:
MOD_FILEPATH    <- file.path("C:/Users/Cristina/Documents/workspace/Edad_con_salud_Fichero_Mod.dta")
CURRENT_FILEPATH   <- file.path(CCOVID_DIR, CURRENT_FILENAME)
RESTORE_FILEPATH   <- file.path(HISTORY_DIR, RESTORE_FILENAME)
BACKUP_FILEPATH    <- file.path(HISTORY_DIR, BACKUP_FILENAME)
CHANGELOG_FILEPATH <- file.path(CCOVID_DIR, CHANGELOG_FILENAME)

STATA_POST_CHANGES_SCRIPT <- "re-run.do"
THROUGHPUT_FILEPATH       <- "throughput.dta"

# The resulting "file" is set to a local "test path" in test mode; only when
#   this process is finally implemented it is set to its actual path.
NEW_FILEPATH <- if (IS_TEST) "test.dta" else CURRENT_FILEPATH
```

# Summary
When implementing the harmonization of the __Edad con Salud database__ - COVID 
sub-study, errors were detected in some variables, such as 102 missing cases in
the variable FECHAFIN. This error was reported to DEMOMETRICA and they returned 
the database updated in these new variables. Along with a change in the nature 
of the variable, it is necessary to re-execute the changes that have been made 
in the COVID sub-study change history. 

The latest version of the COVID sub-study dataset available contains errors due
to the UTF-8 encoding and the structure of the variables that DEMOMETRICA 
modified, especially FECHAFIN.

This script tries to re-execute those changes and finally fix the changes in 
the FECHAFIN variable from factor format with numeric labels (1-8) to date
format. 

This script updates the codification of those variables to the proper UTF-8
encoding, implementing the process through the following steps:

1. Back up the current raw database file.

1. Use the modified version as the new base version, on which to perform the
   subsequent changes.

1. Re-run the changes that were performed in the last update (the one before
Demometrica).

1. Re-run all the changes that have been performed in the subsequent updated of
   the dataset.

1. Check that the datasets are equivalent, except for those variables where
   encoding errors were found.

1. Save the version with these changes to the raw dataset file path.
   
It has been tested that, with the current environment, the encoding is properly
saved with `haven::write_dta()`. Therefore, no additional processing needs to
be done, apparently.

# Update process implementation

## Raw DB file backup

We make a backup of the current DB file in the history.
It is important to stop the process in case the backup copy is not correctly
made, so we add that condition.

```{r backup-dataset, eval=!IS_TEST}
backup_ok <- file.copy(CURRENT_FILEPATH, BACKUP_FILEPATH)

if (!backup_ok) stop("Backup of current dataset file failed.")
```

## Open the `r RESTORE_FILENAME` historical version to restore

```{r load-restore-dataset}
#historico_covid <- read_dta(RESTORE_FILEPATH)
mod_covid <- read_dta(MOD_FILEPATH)
```

## Re-run all the subsequent changes

The changes in the changelog file are first read and output to a Stata "do file"
along with the dataset with the time and period variables updated.

```{r preprocesss-post-changes}
changelog <- read_excel(CHANGELOG_FILEPATH)

# The syntax of the subsequent changes are read from the changelog Excel file
syntax_lines <- changelog                                  |>
  filter(`RESPONSABLE (cualquier investigador)`!="Cris") |>
  slice(-1)                                                |>
  # Assign syntactically-correct name (the one in the changelog is very long):
  rename_at(5, ~"Syntax")                                  |>
  pull(Syntax)

# These syntax lines are then written (along with a temporary dataset) to a
#   ".do" file (re-run.do), to be executed in Stata (see next chunk, labelled
#   `rerun-post-changes`).
syntax_lines    |> write_lines(STATA_POST_CHANGES_SCRIPT)
mod_covid |> write_dta(THROUGHPUT_FILEPATH, version = STATA_VERSION)
```

The subsequent changes are then run in Stata.

```{stata rerun-post-changes}
use "throughput.dta"

do re-run.do

saveold "throughput.dta", replace version(13)
```

The dataset is read back again, taking into account that the "UTF-8" encoding
must be explicitly specified.

```{r read-implemented-changes}
# Encoding must be specified for Stata 13 files
mod_covid <- read_dta(THROUGHPUT_FILEPATH, encoding = "UTF-8")
```

## Check equivalence of datasets

The newly created dataset is compared with the current version, to scan for
differences. In order to avoid a long output, we read with the "wrong encoding"
the new dataset, and compare it with the current version; this one has to be
read in UTF-8, as the errors are "correctly coded" in UTF-8

```{r check-equivalence}
dataset_current <- read_dta(CURRENT_FILEPATH) #, encoding = "UTF-8")
dataset_compare <- read_dta(THROUGHPUT_FILEPATH)

compare(dataset_current, dataset_compare, max_diffs = Inf)
```


<!-- Then we write again the "throughput dataset", and repeat the process. We expect -->
<!-- that no differences are found now between the two objects. -->

<!-- ```{r recheck-equivalence} -->
<!-- dataset_updated |> write_dta(THROUGHPUT_FILEPATH, version = STATA_VERSION) -->

<!-- dataset_current <- read_dta(CURRENT_FILEPATH, encoding = "UTF-8") -->
<!-- dataset_compare <- read_dta(THROUGHPUT_FILEPATH) -->

<!-- compare(dataset_current, dataset_compare, max_diffs = Inf) -->
<!-- ``` -->

<!-- Now we see that the two objects are exactly the same. -->

<!-- ## New dataset writing -->

<!-- The updated dataset is written back to the main raw dataset path. -->

<!-- ```{r write-updated-dataset} -->
<!-- dataset_updated |> write_dta(NEW_FILEPATH, version = STATA_VERSION) -->
<!-- ``` -->

<!-- # Final clean-up -->

<!-- Throughput files are cleaned up. -->

<!-- ```{r cleanup, results='hide'} -->
<!-- file.remove(THROUGHPUT_FILEPATH, STATA_POST_CHANGES_SCRIPT) -->
<!-- ``` -->

# Session info

```{r session-info}
session_info()
```

