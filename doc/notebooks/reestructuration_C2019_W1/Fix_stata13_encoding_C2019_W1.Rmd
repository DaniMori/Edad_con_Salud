---
title: "Correction of free-text variables in Cohort 2019 - Wave 1"
output:
  html_document:
    toc:             yes
    toc_float:       yes
    df_print:        paged
    code_folding:    hide
    code_download:   yes
params:
  test:              yes
editor_options: 
  chunk_output_type: console
---

```{r setup, message=FALSE}
library(knitr)
library(ecs.data)
library(tidyverse)
library(lubridate)
library(readr)
library(haven)
library(glue)
library(rlang)
library(readxl)
library(RStata)

opts_chunk$set(echo = TRUE, results = 'asis')
```

```{r functions}
print_date <- stamp(
  "01/01/1960",
  orders = "dmy",
  locale = "Spanish_Spain.1252"
)
suppressMessages(
  print_datetime <- stamp(
    "1960-01-01_23-59-59",
    orders = "ymd_HMS",
    locale = "Spanish_Spain.1252"
  )
)
```

```{r constants}
# Execution configuration: ----
IS_TEST <- params$test

# Data values and variables objects: ----

STATA_VERSION <- 13L

## Date and time objects:

SEC_24H          <- 60L * 60L * 24L

DEFAULT_DATE     <- dmy("01-01-1960")
default_date_out <- print_date(DEFAULT_DATE)

ORIGINAL_CHANGE_DATE <- dmy("10-03-2022") |> print_date()
CHANGE_DATETIME      <- now()             |> print_datetime()

# File system objects: ----

## Current file structure:

### Folders:

DB_ROOT_DIR    <- read_ecs_folder("DB")
C2019W1_SUBDIR <- "Ola_3/Cohorte_2019"
C2011W3_SUBDIR <- "Ola_3/Cohorte_2011/FINAL"
HISTORY_SUBDIR <- "history"
C2019W1_DIR    <- file.path(DB_ROOT_DIR, C2019W1_SUBDIR)
C2011W3_DIR    <- file.path(DB_ROOT_DIR, C2011W3_SUBDIR)
HISTORY_DIR    <- file.path(C2019W1_DIR, HISTORY_SUBDIR)

### Files:

CURRENT_FILENAME   <- "rawdata_c2019w1.dta"
RESTORE_FILENAME   <- "snapshot_2022-01-12_complete.dta"
# C2011W3_FILENAME      <-
#   "20190208_PES16028242_Seguimiento_final_completo_V6.dta"
BACKUP_FILENAME    <- "snapshot_{CHANGE_DATETIME}.dta" |> glue()
CHANGELOG_FILENAME <- "Modificaciones_BBDD_c2019w1.xlsx"
# C2019W1_PREV_FILENAME <- "snapshot_2022-01-12_complete.dta"
# C2019W1_SPSS_FILENAME <- "PES16028242_MN_Final20210602.sav"

### File paths:

CURRENT_FILEPATH   <- file.path(C2019W1_DIR, CURRENT_FILENAME)
RESTORE_FILEPATH   <- file.path(HISTORY_DIR, RESTORE_FILENAME)
# C2011W3_FILEPATH      <- file.path(C2011W3_DIR, C2011W3_FILENAME)
BACKUP_FILEPATH    <- file.path(HISTORY_DIR, BACKUP_FILENAME)
# C2019W1_PREV_FILEPATH <- file.path(HISTORY_DIR, C2019W1_PREV_FILENAME)
# C2019W1_SPSS_FILENAME <- file.path(HISTORY_DIR, C2019W1_SPSS_FILENAME)
CHANGELOG_FILEPATH <- file.path(C2019W1_DIR, CHANGELOG_FILENAME)

NEW_FILEPATH <- if (IS_TEST) "test.dta" else CURRENT_FILEPATH
```

# Summary

The _Edad con Salud_ raw dataset of Cohort 2019, wave 1 (C2019W1)
[was automatically processed in R][dates_fix] on `r ORIGINAL_CHANGE_DATE`.
This dataset contains errors in the free-text variables.
This is due to, when doing that processing, the codification of those variables
was inadvertently changed.

[dates_fix]: https://dauam-my.sharepoint.com/:x:/r/personal/marta_miret_uam_es/Documents/Edad%20con%20Salud/Bases%20de%20datos%20maestras%20Edad%20con%20Salud/Ola_3/Cohorte_2019/Modificaciones_BBDD_c2019w1.xlsx

This script updates the codification of those variables to the proper UTF-8
encoding, implementing the process through the following steps:

1. Back up the current raw database file.

1. Use the historical version ``r RESTORE_FILENAME`` (the last one known to
   have the proper encoding) as the new base version, on which to perform the
   subsequent changes.

1. Re-run the changes that were performed in the `r ORIGINAL_CHANGE_DATE`
   update.

1. Re-run all the changes that have been performed in the subsequent updated of
   the dataset.

1. Check that all the variables are equivalent, except for those where encoding
   errors are found.

1. Save the version with these changes to the raw dataset file path.
   
It has been tested that, with the current environment, the encoding is properly
saved with `haven::write_dta()`. Therefore, no additional processing needs to
be done, apparently.

# Update process implementation

## Raw DB file backup

We make a backup of the current DB file in the history.
It is important to stop the process in case the backup copy is not correctly
made, so we add that condition.

```{r backup-dataset, eval=!IS_TEST}
backup_ok <- file.copy(CURRENT_FILEPATH, BACKUP_FILEPATH)

if (!backup_ok) stop("Backup of current dataset file failed.")
```

## Open the `r RESTORE_FILENAME` historical version to restore

```{r load-restore-dataset}
dataset_c2019w1 <- read_dta(RESTORE_FILEPATH)
```

## Re-run of the `r ORIGINAL_CHANGE_DATE` update changes

```{r affected-vars}
PERIOD_VARS <- c(
  "q7013_time", "q7014_time",
  "q7026", "q7027", "q7066", "q7067", "q7111", "q7112"
)
TIMESTAMP_VARS <- quo(matches("time_"))
```

As per the previous version of the `.Rmd` file with these changes:

> Using the "default date" as origin, [the period and timestamp variables] are
> formatted as the data type used by Stata (POSIX-long time). It is also
> necessary to use "universal time coordinates" to avoid that the computer local
> time converts the hours as a function of its time zone configured. We use thus
> the standard time zone or "GMT".

```{r update-values}
dataset_updated <- dataset_c2019w1 |> mutate(
  across(
    c(all_of(PERIOD_VARS), !!TIMESTAMP_VARS),
    as.POSIXlt, origin = DEFAULT_DATE, tz = "GMT"
  )
)
```

## Re-run all the subsequent changes

```{r rerun-changes}
changelog <- read_excel(CHANGELOG_FILEPATH)

syntax_lines <- changelog                                  |>
  filter(`FECHA DE IMPLEMENTACIÃ“N` > ORIGINAL_CHANGE_DATE) |>
  rename_at(5, ~"Syntax")                 |> # Assign syntactically-correct name
  select(Syntax)                                           |>
  slice(-1)                                                |>
  pull()


```

## Check variables equivalence

## Escritura del nuevo archivo de datos

```{r write-updated-dataset}
dataset_updated |> write_dta(NEW_FILEPATH, version = STATA_VERSION)
```

